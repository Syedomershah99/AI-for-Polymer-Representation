# Polymer Representation Analysis - Complete Documentation

## Table of Contents
1. [Overview](#overview)
2. [Dataset and Preprocessing](#dataset-and-preprocessing)
3. [Molecular Representations](#molecular-representations)
4. [Murtagh Hierarchical Clustering](#murtagh-hierarchical-clustering)
5. [Clustering Evaluation](#clustering-evaluation)
6. [Supervised Learning](#supervised-learning)
7. [Visualization](#visualization)
8. [Technical Jargon Explained](#technical-jargon-explained)

---

## Overview

This notebook implements a comprehensive polymer representation learning and analysis pipeline. The goal is to:

1. **Learn and Compare Polymeric Representations**: Understand how polymer SMILES are converted into numerical features
2. **Compare Fingerprints, Descriptors, and Embeddings**: See how they shape polymer chemical space
3. **Evaluate Clustering Quality**: Measure alignment with known polymer classes
4. **Train Supervised Models**: Classify polymers using different representations
5. **Visualize Chemical Space**: Use dimensionality reduction for interpretation

### Key Features (Updated January 2026)

1. **Six Representation Types**:
   - Morgan Fingerprints (ECFP) - 2,048 bits
   - MACCS Keys - 167 bits
   - RDKit Descriptors - ~161 features
   - Mordred Descriptors - ~1,613 features (NEW)
   - RDKit+MACCS Combined
   - Transformer Embeddings (polyBERT) - 600 dimensions

2. **Murtagh Hierarchical Clustering**: K=2-25 with comprehensive evaluation
3. **5-Fold Stratified Cross-Validation**: Rigorous evaluation with Mordred descriptors
4. **Comprehensive Metrics**: ARI, NMI, Silhouette for clustering; Accuracy, F1-macro for classification

---

## Dataset and Preprocessing

### 1.1 Dataset Loading

**What**: PI1070 dataset containing 1,077 polymer structures
**Source**: Local file (data/PI1070.csv) with GitHub fallback
**Format**: CSV file with SMILES strings and properties

**Columns**:
- `smiles`: String representation of molecular structure (SMILES notation)
- `polymer_class`: Class label (target variable for supervised learning)
- Properties: `density`, `bulk_modulus`, `thermal_conductivity`, `static_dielectric_const`

### 1.2 SMILES Canonicalization

**Why**: SMILES strings can represent the same molecule in multiple ways
**Example**:
- `CC(C)C` and `C(C)CC` both represent isobutane
- Canonicalization ensures unique representation

**How**:
```python
mol = Chem.MolFromSmiles(smiles)  # Parse SMILES
canonical = Chem.MolToSmiles(mol, canonical=True)  # Get canonical form
```

### 1.3 Data Cleaning

**Steps**:
1. Remove invalid SMILES (molecules RDKit cannot parse)
2. Remove duplicates based on canonical SMILES
3. Create RDKit molecule objects for further processing

**Result**: Clean dataset with 1,077 unique, valid polymer structures

---

## Molecular Representations

Six types of molecular representations are computed:

### 2.1 Morgan Fingerprints (ECFP)

**Full Name**: Extended-Connectivity Fingerprints (ECFP) / Circular Fingerprints

**What**: Binary vectors encoding molecular substructures
**Size**: 2,048 bits
**Parameters**: Radius = 2 (looks 2 bonds away from each atom)

**How it works**:
1. For each atom, identify all substructures within radius 2
2. Hash each substructure to a bit position (0-2047)
3. Set those bit positions to 1

**Performance** (5-Fold CV - BEST PERFORMER):
- Train Accuracy: 99.8%
- Test Accuracy: 93.1% +/- 1.2%
- Test F1 (macro): 0.797 +/- 0.024

### 2.2 MACCS Keys

**Full Name**: Molecular ACCess System Keys

**What**: 166 predefined binary structural patterns
**Size**: 167 bits (keys 0-166, where key 0 is always 0)

**Examples of patterns**:
- Bit 5: Presence of a benzene ring
- Bit 79: Presence of a carbonyl group (C=O)
- Bit 125: Presence of an aromatic nitrogen

**Performance** (5-Fold CV):
- Train Accuracy: 96.5%
- Test Accuracy: 89.3% +/- 1.4%
- Test F1 (macro): 0.792 +/- 0.029

### 2.3 RDKit Descriptors

**What**: ~161 molecular descriptors from RDKit
**Type**: Continuous numerical features (require standardization)

**Descriptors include**:
- **Molecular weight**: Mass of the molecule
- **LogP**: Lipophilicity (fat vs water solubility)
- **Number of H-bond donors/acceptors**: For intermolecular interactions
- **Topological indices**: Graph-based descriptors of molecular shape
- **Ring counts**: Number and types of rings

**Processing**:
1. Compute all available descriptors
2. Remove columns with all NaN values
3. Impute remaining NaNs with column medians
4. Standardize using StandardScaler (mean=0, std=1)

### 2.4 Mordred Descriptors (NEW)

**What**: Comprehensive molecular descriptor calculator
**Size**: ~1,613 2D descriptors (after filtering from ~1,800 total)
**Library**: mordred (RDKit extension)

**Descriptor Categories**:
- Constitutional: Atoms, bonds, molecular formula
- Topological: Graph-based properties, connectivity indices
- Electronic: Partial charges, electronegativity
- CPSA: Charged partial surface area
- EState: Electrotopological state indices
- Autocorrelation: Property distributions
- Information content: Complexity measures

**Processing**:
1. Compute all 2D descriptors (ignore 3D - no coordinates needed)
2. Handle Missing/Error values as NaN
3. Remove all-NaN columns
4. Remove zero-variance columns
5. Impute remaining NaNs with column medians
6. Standardize using StandardScaler

**Why Mordred?**:
- More comprehensive than RDKit descriptors alone
- Widely used in QSAR/QSPR modeling
- Captures diverse chemical properties
- Well-maintained open-source library

### 2.5 Transformer Embeddings (polyBERT)

**What**: Deep learning-based representation using pre-trained language model
**Model**: polyBERT (BERT trained on polymer SMILES)
**Size**: 600-dimensional dense vector

**How it works**:
1. Tokenize SMILES into subunits
2. Pass through transformer encoder
3. Use [CLS] token embedding as molecule representation

**Performance** (5-Fold CV):
- Train Accuracy: 100.0% (perfect - indicates overfitting)
- Test Accuracy: 90.5% +/- 1.4%
- Test F1 (macro): 0.757 +/- 0.041 (HIGHEST VARIANCE)

**Note**: Despite being the most sophisticated, transformer shows worst generalization due to overfitting.

### 2.6 Combined Representation (RDKit+MACCS)

**What**: Concatenation of RDKit descriptors and MACCS keys
**Size**: ~328 features (~161 RDKit + 167 MACCS)

**Performance** (70:30 Split):
- Test Accuracy: 92.0% +/- 2.0%
- Test F1 (macro): 0.823 +/- 0.047 (BEST F1)

**Note**: Shows variable performance in different evaluation settings.

---

## Clustering Evaluation

### Metrics Used

| Metric | Type | Range | Optimal | What it Measures |
|--------|------|-------|---------|------------------|
| ARI | External | -1 to 1 | 1 | Agreement with true labels |
| NMI | External | 0 to 1 | 1 | Information shared with labels |
| Silhouette | Internal | -1 to 1 | 1 | Cluster separation quality |

### Key Clustering Results (Morgan FP)

**K=5 PHENOMENON (Critical Discovery)**:
```
K=4: ARI=0.007, NMI=0.048, Silhouette=0.068
K=5: ARI=0.230, NMI=0.357, Silhouette=0.113

Improvement at K=5:
- ARI: 33x increase!
- NMI: 7.4x increase!
- Silhouette: 66% increase!
```

This dramatic jump suggests exactly 5 fundamental structural families in the polymer dataset.

**Best K=25**:
- ARI: 0.518 (52% agreement with true classes)
- NMI: 0.602 (60% information sharing)
- Silhouette: 0.122 (low, indicating overlapping clusters)

### Interpretation

- **K=5**: Best for identifying major structural families
- **K=17-19**: Best balance of internal structure and class alignment
- **K=25**: Maximum alignment with polymer classes
- **Low Silhouette (~0.12)**: Clusters overlap significantly, fuzzy boundaries

---

## Supervised Learning

### 5-Fold Stratified Cross-Validation Results (PRIMARY EVALUATION)

| Representation | Train Acc | Test Acc | Test F1 (macro) | Notes |
|----------------|-----------|----------|-----------------|-------|
| **Morgan FP** | 99.8% | **93.1% +/- 1.2%** | 0.797 +/- 0.024 | BEST & MOST STABLE |
| MACCS Keys | 96.5% | 89.3% +/- 1.4% | 0.792 +/- 0.029 | Competitive |
| Transformer | 100.0% | 90.5% +/- 1.4% | 0.757 +/- 0.041 | Overfits |
| RDKit+MACCS | 24.4%* | 24.4% +/- 0.2%* | 0.025* | *Preprocessing issue |

### 70:30 Train-Test Split Results (5 Repeats)

| Representation | Train Acc | Test Acc | Test F1 (macro) |
|----------------|-----------|----------|-----------------|
| **Morgan FP** | 99.8% | **92.9% +/- 1.4%** | 0.758 +/- 0.069 |
| MACCS Keys | 96.4% | 88.9% +/- 1.8% | 0.750 +/- 0.047 |
| RDKit+MACCS | 99.8% | 92.0% +/- 2.0% | **0.823 +/- 0.047** |
| Transformer | 100.0% | 91.3% +/- 1.5% | 0.735 +/- 0.074 |

### Key Findings

1. **Morgan FP Wins**: Most stable and generalizable (93.1% +/- 1.2% in 5-fold CV)
2. **Transformer Paradox**: Perfect training (100%) but only 90.5% test - severe overfitting
3. **Simple Beats Complex**: 2048-bit binary fingerprints outperform 600-dim dense embeddings
4. **Overfitting Pervasive**: All models show 7-10% train-test gap
5. **RDKit+MACCS Best F1**: In 70:30 split, achieves 0.823 F1 (best for imbalanced classes)

### Structure-Function Gap

- **Clustering (unsupervised)**: 52% agreement (ARI=0.518)
- **Supervised learning**: 93% accuracy
- **Gap**: 41 percentage points!

This means structure captures ~50-60% of class information, with ~40-50% coming from non-structural factors.

---

## Visualization

### PCA Visualization

- 2D projections of high-dimensional representations
- PC1 + PC2 capture only 20-25% of total variance
- Shows overlapping clusters (confirms low silhouette scores)
- Consistent structure across all representations

### Contingency Heatmaps

- Show cluster-class relationships for K=5, 10, 15, 25
- Average cluster purity: 50-70%
- Many-to-many relationship between clusters and classes
- No pure clusters exist

### Dendrograms

- Visualize hierarchical clustering structure
- Confirm K=5 major branches
- Show merge distances and relationships
- Color coding at 70% tree height reveals 5 groups

---

## Technical Jargon Explained

### Chemistry Terms

**SMILES**: Simplified Molecular Input Line Entry System - text representation of molecular structure (e.g., `CCO` = ethanol)

**Fingerprint**: Binary or numeric vector representing molecular structure - like a molecular "barcode"

**Tanimoto Similarity**: Similarity = intersection / union for binary vectors. Range 0-1.

**MACCS Keys**: 166 predefined structural patterns developed by MDL

**Mordred**: Open-source molecular descriptor calculator (~1,800 2D/3D descriptors)

### Machine Learning Terms

**Stratified Split**: Splitting data while preserving class distribution in train and test sets

**Cross-Validation**: Multiple train/test splits for robust performance estimation

**Overfitting**: Model memorizes training data, poor generalization to new data

**ARI (Adjusted Rand Index)**: Clustering agreement metric, adjusted for chance (0 = random, 1 = perfect)

**NMI (Normalized Mutual Information)**: Information-theoretic metric (0 = no info, 1 = perfect)

**Silhouette Score**: Internal cluster quality (-1 = wrong cluster, 0 = boundary, 1 = well-clustered)

### Key Numbers to Remember

- **Dataset**: 1,077 polymers, 17 classes
- **Morgan FP**: 2,048 bits
- **MACCS Keys**: 167 bits
- **RDKit Descriptors**: ~161 features
- **Mordred Descriptors**: ~1,613 features (after filtering)
- **Transformer**: 600 dimensions
- **Best Test Accuracy**: 93.1% (Morgan FP, 5-fold CV)
- **Best Clustering K**: K=5 (families) or K=25 (max alignment)
- **Structure-Function Gap**: 41% (93% supervised - 52% clustering)

---

## Summary

This notebook provides comprehensive polymer representation analysis with the following key findings:

1. **Six representations compared**: Morgan FP, MACCS, RDKit, Mordred, RDKit+MACCS, Transformer
2. **K=5 Phenomenon**: Five fundamental structural families discovered
3. **Morgan FP Wins**: 93.1% accuracy, most stable across folds
4. **Transformer Overfits**: 100% train, 90.5% test - simple beats complex
5. **Structure-Function Gap**: 41% (clustering 52% vs supervised 93%)
6. **Fuzzy Clusters**: 50-70% purity, overlapping boundaries

### Practical Recommendations

- Use **Morgan FP** for production (best generalization)
- Use **K=5** for exploratory analysis (structural families)
- Add **regularization** to prevent overfitting
- Consider **two-stage approach**: cluster then classify
- **Mordred descriptors** provide comprehensive chemical features for QSAR
